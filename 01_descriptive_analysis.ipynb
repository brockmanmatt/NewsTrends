{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instructions for how to build this using nbdev at https://nbdev.fast.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe loaded articles\n",
    "\n",
    "> Takes a loader as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from newstrends import loader\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class describer(loader.article_holder):\n",
    "    \"inherit everything from article_holder including init\"\n",
    "    \n",
    "    subclass=\"describer\"\n",
    "    vectorizer=None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = loader.article_holder()\n",
    "assert(type(tmp)==loader.article_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'article_holder'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'describer'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = describer()\n",
    "tmp.subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure that I can still use article_holder functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ah = describer()\n",
    "test_ah.set_articleDir(\"../CoverageTrends\")\n",
    "try:\n",
    "    test_ah.load_articles(publications=[\"newyorktimes\"])\n",
    "    assert (\"quickReplace\" in test_ah.df.columns)\n",
    "except:\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class describer(describer):\n",
    "    \"Add in vectorize\"\n",
    "    \n",
    "    def fitVectorizer(self, vectorizer:CountVectorizer=CountVectorizer, ngram_range=(1,2), max_features=10000):\n",
    "        try:\n",
    "            _ = self.df[:1].quickReplace\n",
    "        except:\n",
    "            raise Exception(\"No article data found\")\n",
    "        \n",
    "        self.vectorizer=vectorizer(stop_words=self.stopwords, ngram_range=ngram_range, max_features=max_features).fit(self.df.quickReplace)        \n",
    "    \n",
    "    def getTopNWords(self, topN = 10, lastDate=None, window=None, source=None):        \n",
    "        \" get topN important words for each publication \"\n",
    "\n",
    "        \"check if properly formatted\"\n",
    "        if type(self.df) != pd.core.frame.DataFrame:\n",
    "            raise Exception(\"Dataframe not loaded\")\n",
    "        if self.vectorizer == None:\n",
    "            raise Exception(\"No vectorizer found\")\n",
    "        \n",
    "        \n",
    "        \"Get Dataframe for source and time period\"\n",
    "        sources=source\n",
    "        if source==None:\n",
    "            sources=[x for x in self.df.source.unique()]\n",
    "        df = self.df[self.df.source.isin(sources)]\n",
    "        \n",
    "        \"get counts of features from count vectorizer\"\n",
    "        X = self.vectorizer.transform(df.quickReplace)\n",
    "        vocab = list(self.vectorizer.get_feature_names())\n",
    "        counts = X.sum(axis=0).A1\n",
    "        counts = Counter(dict(zip(vocab, counts)))\n",
    "\n",
    "        return counts.most_common(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure exceptions thrown on empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ah = describer()\n",
    "try:\n",
    "    test_ah.fitVectorizer()\n",
    "    assert False\n",
    "except:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try loading in new york times data to test vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = describer()\n",
    "test.set_articleDir(path=\"../CoverageTrends\")\n",
    "test.load_articles(publications=[\"newyorktimes\"])\n",
    "test.fitVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 3378),\n",
       " ('time', 2846),\n",
       " ('citi', 2801),\n",
       " ('protest', 2312),\n",
       " ('coronavirus', 1773),\n",
       " ('pandem', 1610),\n",
       " ('presid', 1589),\n",
       " ('press', 1458),\n",
       " ('polic', 1428),\n",
       " ('death', 1403)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.getTopNWords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class describer(describer):\n",
    "    \"Now having cooccurances could be nice\"\n",
    "    \n",
    "    def generateCoOccurances(self, pubList = [\"newyorktimes\", \"foxnews\", \"washingtonpost\", \"cnn\", \"breitbart\", \"abcnews\", \"dailycaller\"], verbose=False, topK:\"int<100\" = 20):\n",
    "        \" get cooccurances of terms in my df, up to 100\"\n",
    "        \n",
    "        if type(self.df) != pd.core.frame.DataFrame:\n",
    "            raise Exception(\"Dataframe not loaded\")\n",
    "        if self.vectorizer == None:\n",
    "            raise Exception(\"No vectorizer found\")\n",
    "            \n",
    "        vectorizer = CountVectorizer(stop_words=self.stopwords, max_features=10000).fit(self.df.quickReplace)   \n",
    "\n",
    "        # get the transformed DF\n",
    "        X = vectorizer.transform(self.df.quickReplace)\n",
    "        X[X > 0] = 1\n",
    "\n",
    "        coOccurance = (X.T * X)\n",
    "        coOccurance.setdiag(0)\n",
    "        d = coOccurance.todense()\n",
    "        \n",
    "        checkLength = topK*2\n",
    "        if checkLength > 100:\n",
    "            checkLength = 100\n",
    "\n",
    "        top_prs = np.dstack(np.unravel_index(np.argpartition(d.ravel(),-checkLength)[:,-checkLength:],d.shape))[0]\n",
    "\n",
    "        vals = []\n",
    "        keys = vectorizer.get_feature_names()\n",
    "        for pair in top_prs:\n",
    "            newEntry = [keys[pair[0]], keys[pair[1]]]\n",
    "            if newEntry not in vals:\n",
    "                vals.append(newEntry)\n",
    "            if len(vals) >= topK:\n",
    "                break\n",
    "\n",
    "        #So now for each day for each time period I want to math out the co-occurances!\n",
    "        return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = describer()\n",
    "test.set_articleDir(path=\".\")\n",
    "test.load_articles(publications=[\"newyorktimes\"])\n",
    "test.fitVectorizer()\n",
    "\n",
    "assert(len(test.generateCoOccurances(topK=15))==15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
